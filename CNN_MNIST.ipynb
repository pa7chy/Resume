{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, elapsed time 0.34 seconds, training accuracy 36.000%\n",
      "step 100, elapsed time 1.07 seconds, training accuracy 84.000%\n",
      "step 200, elapsed time 1.79 seconds, training accuracy 86.000%\n",
      "step 300, elapsed time 2.50 seconds, training accuracy 90.000%\n",
      "step 400, elapsed time 3.21 seconds, training accuracy 94.000%\n",
      "step 500, elapsed time 3.91 seconds, training accuracy 94.000%\n",
      "step 600, elapsed time 4.62 seconds, training accuracy 98.000%\n",
      "step 700, elapsed time 5.33 seconds, training accuracy 100.000%\n",
      "step 800, elapsed time 6.03 seconds, training accuracy 92.000%\n",
      "step 900, elapsed time 6.76 seconds, training accuracy 98.000%\n",
      "step 1000, elapsed time 7.46 seconds, training accuracy 100.000%\n",
      "step 1100, elapsed time 8.25 seconds, training accuracy 100.000%\n",
      "step 1200, elapsed time 8.95 seconds, training accuracy 96.000%\n",
      "step 1300, elapsed time 9.66 seconds, training accuracy 98.000%\n",
      "step 1400, elapsed time 10.37 seconds, training accuracy 96.000%\n",
      "step 1500, elapsed time 11.08 seconds, training accuracy 100.000%\n",
      "step 1600, elapsed time 11.80 seconds, training accuracy 98.000%\n",
      "step 1700, elapsed time 12.50 seconds, training accuracy 98.000%\n",
      "step 1800, elapsed time 13.21 seconds, training accuracy 100.000%\n",
      "step 1900, elapsed time 13.93 seconds, training accuracy 98.000%\n",
      "step 2000, elapsed time 14.64 seconds, training accuracy 96.000%\n",
      "step 2100, elapsed time 15.34 seconds, training accuracy 98.000%\n",
      "step 2200, elapsed time 16.15 seconds, training accuracy 96.000%\n",
      "step 2300, elapsed time 16.87 seconds, training accuracy 100.000%\n",
      "step 2400, elapsed time 17.57 seconds, training accuracy 94.000%\n",
      "step 2500, elapsed time 18.28 seconds, training accuracy 96.000%\n",
      "step 2600, elapsed time 18.98 seconds, training accuracy 100.000%\n",
      "step 2700, elapsed time 19.69 seconds, training accuracy 98.000%\n",
      "step 2800, elapsed time 20.39 seconds, training accuracy 100.000%\n",
      "step 2900, elapsed time 21.11 seconds, training accuracy 98.000%\n",
      "step 3000, elapsed time 21.82 seconds, training accuracy 98.000%\n",
      "step 3100, elapsed time 22.53 seconds, training accuracy 100.000%\n",
      "step 3200, elapsed time 23.24 seconds, training accuracy 100.000%\n",
      "step 3300, elapsed time 24.02 seconds, training accuracy 98.000%\n",
      "step 3400, elapsed time 24.73 seconds, training accuracy 98.000%\n",
      "step 3500, elapsed time 25.44 seconds, training accuracy 100.000%\n",
      "step 3600, elapsed time 26.15 seconds, training accuracy 98.000%\n",
      "step 3700, elapsed time 26.86 seconds, training accuracy 100.000%\n",
      "step 3800, elapsed time 27.57 seconds, training accuracy 100.000%\n",
      "step 3900, elapsed time 28.29 seconds, training accuracy 98.000%\n",
      "step 4000, elapsed time 29.00 seconds, training accuracy 98.000%\n",
      "step 4100, elapsed time 29.71 seconds, training accuracy 96.000%\n",
      "step 4200, elapsed time 30.41 seconds, training accuracy 100.000%\n",
      "step 4300, elapsed time 31.12 seconds, training accuracy 100.000%\n",
      "step 4400, elapsed time 31.90 seconds, training accuracy 100.000%\n",
      "step 4500, elapsed time 32.61 seconds, training accuracy 100.000%\n",
      "step 4600, elapsed time 33.31 seconds, training accuracy 100.000%\n",
      "step 4700, elapsed time 34.01 seconds, training accuracy 100.000%\n",
      "step 4800, elapsed time 34.72 seconds, training accuracy 100.000%\n",
      "step 4900, elapsed time 35.42 seconds, training accuracy 98.000%\n",
      "step 5000, elapsed time 36.14 seconds, training accuracy 98.000%\n",
      "step 5100, elapsed time 36.85 seconds, training accuracy 98.000%\n",
      "step 5200, elapsed time 37.55 seconds, training accuracy 100.000%\n",
      "step 5300, elapsed time 38.26 seconds, training accuracy 98.000%\n",
      "step 5400, elapsed time 38.97 seconds, training accuracy 100.000%\n",
      "step 5500, elapsed time 39.76 seconds, training accuracy 98.000%\n",
      "step 5600, elapsed time 40.46 seconds, training accuracy 100.000%\n",
      "step 5700, elapsed time 41.18 seconds, training accuracy 100.000%\n",
      "step 5800, elapsed time 41.89 seconds, training accuracy 100.000%\n",
      "step 5900, elapsed time 42.61 seconds, training accuracy 100.000%\n",
      "step 6000, elapsed time 43.33 seconds, training accuracy 100.000%\n",
      "step 6100, elapsed time 44.04 seconds, training accuracy 98.000%\n",
      "step 6200, elapsed time 44.74 seconds, training accuracy 100.000%\n",
      "step 6300, elapsed time 45.45 seconds, training accuracy 98.000%\n",
      "step 6400, elapsed time 46.17 seconds, training accuracy 98.000%\n",
      "step 6500, elapsed time 46.88 seconds, training accuracy 100.000%\n",
      "step 6600, elapsed time 47.68 seconds, training accuracy 100.000%\n",
      "step 6700, elapsed time 48.38 seconds, training accuracy 98.000%\n",
      "step 6800, elapsed time 49.09 seconds, training accuracy 100.000%\n",
      "step 6900, elapsed time 49.79 seconds, training accuracy 100.000%\n",
      "step 7000, elapsed time 50.50 seconds, training accuracy 100.000%\n",
      "step 7100, elapsed time 51.21 seconds, training accuracy 100.000%\n",
      "step 7200, elapsed time 51.93 seconds, training accuracy 100.000%\n",
      "step 7300, elapsed time 52.63 seconds, training accuracy 100.000%\n",
      "step 7400, elapsed time 53.34 seconds, training accuracy 100.000%\n",
      "step 7500, elapsed time 54.06 seconds, training accuracy 100.000%\n",
      "step 7600, elapsed time 54.77 seconds, training accuracy 100.000%\n",
      "step 7700, elapsed time 55.56 seconds, training accuracy 100.000%\n",
      "step 7800, elapsed time 56.29 seconds, training accuracy 100.000%\n",
      "step 7900, elapsed time 57.00 seconds, training accuracy 98.000%\n",
      "step 8000, elapsed time 57.70 seconds, training accuracy 100.000%\n",
      "step 8100, elapsed time 58.41 seconds, training accuracy 100.000%\n",
      "step 8200, elapsed time 59.12 seconds, training accuracy 100.000%\n",
      "step 8300, elapsed time 59.83 seconds, training accuracy 100.000%\n",
      "step 8400, elapsed time 60.53 seconds, training accuracy 100.000%\n",
      "step 8500, elapsed time 61.25 seconds, training accuracy 100.000%\n",
      "step 8600, elapsed time 61.96 seconds, training accuracy 100.000%\n",
      "step 8700, elapsed time 62.67 seconds, training accuracy 100.000%\n",
      "step 8800, elapsed time 63.46 seconds, training accuracy 100.000%\n",
      "step 8900, elapsed time 64.16 seconds, training accuracy 100.000%\n",
      "step 9000, elapsed time 64.87 seconds, training accuracy 100.000%\n",
      "step 9100, elapsed time 65.58 seconds, training accuracy 100.000%\n",
      "step 9200, elapsed time 66.29 seconds, training accuracy 100.000%\n",
      "step 9300, elapsed time 67.00 seconds, training accuracy 100.000%\n",
      "step 9400, elapsed time 67.71 seconds, training accuracy 100.000%\n",
      "step 9500, elapsed time 68.41 seconds, training accuracy 98.000%\n",
      "step 9600, elapsed time 69.12 seconds, training accuracy 100.000%\n",
      "step 9700, elapsed time 69.83 seconds, training accuracy 98.000%\n",
      "step 9800, elapsed time 70.53 seconds, training accuracy 100.000%\n",
      "step 9900, elapsed time 71.33 seconds, training accuracy 100.000%\n",
      "step 10000, elapsed time 72.04 seconds, training accuracy 98.000%\n",
      "step 10100, elapsed time 72.75 seconds, training accuracy 100.000%\n",
      "step 10200, elapsed time 73.46 seconds, training accuracy 100.000%\n",
      "step 10300, elapsed time 74.16 seconds, training accuracy 100.000%\n",
      "step 10400, elapsed time 74.87 seconds, training accuracy 98.000%\n",
      "step 10500, elapsed time 75.57 seconds, training accuracy 100.000%\n",
      "step 10600, elapsed time 76.29 seconds, training accuracy 100.000%\n",
      "step 10700, elapsed time 77.00 seconds, training accuracy 100.000%\n",
      "step 10800, elapsed time 77.71 seconds, training accuracy 100.000%\n",
      "step 10900, elapsed time 78.42 seconds, training accuracy 100.000%\n",
      "step 11000, elapsed time 79.21 seconds, training accuracy 100.000%\n",
      "step 11100, elapsed time 79.92 seconds, training accuracy 100.000%\n",
      "step 11200, elapsed time 80.63 seconds, training accuracy 100.000%\n",
      "step 11300, elapsed time 81.35 seconds, training accuracy 96.000%\n",
      "step 11400, elapsed time 82.05 seconds, training accuracy 100.000%\n",
      "step 11500, elapsed time 82.76 seconds, training accuracy 100.000%\n",
      "step 11600, elapsed time 83.47 seconds, training accuracy 98.000%\n",
      "step 11700, elapsed time 84.18 seconds, training accuracy 100.000%\n",
      "step 11800, elapsed time 84.88 seconds, training accuracy 100.000%\n",
      "step 11900, elapsed time 85.59 seconds, training accuracy 100.000%\n",
      "step 12000, elapsed time 86.31 seconds, training accuracy 100.000%\n",
      "step 12100, elapsed time 87.11 seconds, training accuracy 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12200, elapsed time 87.82 seconds, training accuracy 100.000%\n",
      "step 12300, elapsed time 88.53 seconds, training accuracy 100.000%\n",
      "step 12400, elapsed time 89.24 seconds, training accuracy 100.000%\n",
      "step 12500, elapsed time 89.95 seconds, training accuracy 100.000%\n",
      "step 12600, elapsed time 90.65 seconds, training accuracy 100.000%\n",
      "step 12700, elapsed time 91.37 seconds, training accuracy 100.000%\n",
      "step 12800, elapsed time 92.08 seconds, training accuracy 100.000%\n",
      "step 12900, elapsed time 92.79 seconds, training accuracy 100.000%\n",
      "step 13000, elapsed time 93.50 seconds, training accuracy 100.000%\n",
      "step 13100, elapsed time 94.21 seconds, training accuracy 100.000%\n",
      "step 13200, elapsed time 95.00 seconds, training accuracy 100.000%\n",
      "step 13300, elapsed time 95.71 seconds, training accuracy 100.000%\n",
      "step 13400, elapsed time 96.43 seconds, training accuracy 100.000%\n",
      "step 13500, elapsed time 97.14 seconds, training accuracy 100.000%\n",
      "step 13600, elapsed time 97.85 seconds, training accuracy 100.000%\n",
      "step 13700, elapsed time 98.57 seconds, training accuracy 100.000%\n",
      "step 13800, elapsed time 99.27 seconds, training accuracy 100.000%\n",
      "step 13900, elapsed time 99.99 seconds, training accuracy 100.000%\n",
      "step 14000, elapsed time 100.69 seconds, training accuracy 100.000%\n",
      "step 14100, elapsed time 101.42 seconds, training accuracy 100.000%\n",
      "step 14200, elapsed time 102.13 seconds, training accuracy 100.000%\n",
      "step 14300, elapsed time 102.93 seconds, training accuracy 100.000%\n",
      "step 14400, elapsed time 103.64 seconds, training accuracy 100.000%\n",
      "step 14500, elapsed time 104.35 seconds, training accuracy 100.000%\n",
      "step 14600, elapsed time 105.06 seconds, training accuracy 100.000%\n",
      "step 14700, elapsed time 105.77 seconds, training accuracy 100.000%\n",
      "step 14800, elapsed time 106.49 seconds, training accuracy 100.000%\n",
      "step 14900, elapsed time 107.20 seconds, training accuracy 100.000%\n",
      "step 15000, elapsed time 107.91 seconds, training accuracy 100.000%\n",
      "step 15100, elapsed time 108.62 seconds, training accuracy 100.000%\n",
      "step 15200, elapsed time 109.33 seconds, training accuracy 100.000%\n",
      "step 15300, elapsed time 110.04 seconds, training accuracy 100.000%\n",
      "step 15400, elapsed time 110.83 seconds, training accuracy 100.000%\n",
      "step 15500, elapsed time 111.56 seconds, training accuracy 100.000%\n",
      "step 15600, elapsed time 112.27 seconds, training accuracy 100.000%\n",
      "step 15700, elapsed time 112.98 seconds, training accuracy 100.000%\n",
      "step 15800, elapsed time 113.69 seconds, training accuracy 100.000%\n",
      "step 15900, elapsed time 114.40 seconds, training accuracy 100.000%\n",
      "step 16000, elapsed time 115.12 seconds, training accuracy 100.000%\n",
      "step 16100, elapsed time 115.83 seconds, training accuracy 100.000%\n",
      "step 16200, elapsed time 116.55 seconds, training accuracy 100.000%\n",
      "step 16300, elapsed time 117.26 seconds, training accuracy 100.000%\n",
      "step 16400, elapsed time 117.97 seconds, training accuracy 100.000%\n",
      "step 16500, elapsed time 118.76 seconds, training accuracy 100.000%\n",
      "step 16600, elapsed time 119.47 seconds, training accuracy 100.000%\n",
      "step 16700, elapsed time 120.18 seconds, training accuracy 100.000%\n",
      "step 16800, elapsed time 120.89 seconds, training accuracy 100.000%\n",
      "step 16900, elapsed time 121.62 seconds, training accuracy 100.000%\n",
      "step 17000, elapsed time 122.35 seconds, training accuracy 100.000%\n",
      "step 17100, elapsed time 123.06 seconds, training accuracy 100.000%\n",
      "step 17200, elapsed time 123.77 seconds, training accuracy 98.000%\n",
      "step 17300, elapsed time 124.49 seconds, training accuracy 100.000%\n",
      "step 17400, elapsed time 125.20 seconds, training accuracy 100.000%\n",
      "step 17500, elapsed time 125.91 seconds, training accuracy 100.000%\n",
      "step 17600, elapsed time 126.74 seconds, training accuracy 100.000%\n",
      "step 17700, elapsed time 127.46 seconds, training accuracy 100.000%\n",
      "step 17800, elapsed time 128.18 seconds, training accuracy 100.000%\n",
      "step 17900, elapsed time 128.89 seconds, training accuracy 100.000%\n",
      "step 18000, elapsed time 129.60 seconds, training accuracy 100.000%\n",
      "step 18100, elapsed time 130.31 seconds, training accuracy 100.000%\n",
      "step 18200, elapsed time 131.05 seconds, training accuracy 100.000%\n",
      "step 18300, elapsed time 131.78 seconds, training accuracy 100.000%\n",
      "step 18400, elapsed time 132.50 seconds, training accuracy 100.000%\n",
      "step 18500, elapsed time 133.21 seconds, training accuracy 100.000%\n",
      "step 18600, elapsed time 133.94 seconds, training accuracy 100.000%\n",
      "step 18700, elapsed time 134.75 seconds, training accuracy 100.000%\n",
      "step 18800, elapsed time 135.47 seconds, training accuracy 100.000%\n",
      "step 18900, elapsed time 136.21 seconds, training accuracy 100.000%\n",
      "step 19000, elapsed time 136.95 seconds, training accuracy 100.000%\n",
      "step 19100, elapsed time 137.67 seconds, training accuracy 100.000%\n",
      "step 19200, elapsed time 138.39 seconds, training accuracy 100.000%\n",
      "step 19300, elapsed time 139.11 seconds, training accuracy 100.000%\n",
      "step 19400, elapsed time 139.83 seconds, training accuracy 100.000%\n",
      "step 19500, elapsed time 140.55 seconds, training accuracy 100.000%\n",
      "step 19600, elapsed time 141.29 seconds, training accuracy 100.000%\n",
      "step 19700, elapsed time 142.02 seconds, training accuracy 100.000%\n",
      "step 19800, elapsed time 142.82 seconds, training accuracy 100.000%\n",
      "step 19900, elapsed time 143.53 seconds, training accuracy 100.000%\n",
      "Total training time for 20000 batches: 144.25 seconds\n",
      "Test accuracy 99.240%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#Use CPU because of GPU OOM issue\n",
    "config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=True\n",
    "#     device_count = {'GPU':0}\n",
    ")\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5    \n",
    "config.gpu_options.allow_growth = True      \n",
    "config.gpu_options.allocator_type = 'BFC'  \n",
    "sess = tf.InteractiveSession(config=config)\n",
    "# sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) #x is placeholder for 28 * 28 image\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape (x, [-1,28,28,1], name=\"x_image\") #change input data from a list to a 28 x 28 x 1 grayscale cube\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #k is kernel\n",
    "# Define layers\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) #32 features for each 5x5 size of filer, 1 channel grayscale\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # convolution\n",
    "h_pool1 = max_pool_2x2(h_conv1) # max pooling\n",
    "W_conv2 = weight_variable([5, 5, 32, 64]) #64 features\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# Fully Connected Layer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) # 7x7 images by 64 features to 1024 neuron \n",
    "b_fc1 = bias_variable([1024])\n",
    "# connect output of pooling 2 to fc layer\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "#dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "#Readout\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "#Define model\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#Loss measurement\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv,labels=y_))\n",
    "                               \n",
    "#Loss optimization\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "#correct\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "#accurate\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Train\n",
    "import time\n",
    "\n",
    "num_steps = 20000\n",
    "display_every = 100\n",
    "\n",
    "#start timer\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "\n",
    "for i in range(num_steps):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob:0.5})\n",
    "    \n",
    "    if i%display_every == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob: 1.0})\n",
    "        end_time = time.time()\n",
    "        print(\"step {0}, elapsed time {1:.2f} seconds, training accuracy {2:.3f}%\".format(i, end_time - start_time, train_accuracy*100))\n",
    "#Display summary\n",
    "end_time = time.time()\n",
    "print(\"Total training time for {0} batches: {1:.2f} seconds\".format(i+1, end_time-start_time))\n",
    "\n",
    "# Accuracy on test data\n",
    "# print(\"Test accuracy {0:.3f}%\".format(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})*100.0))\n",
    "# mnist.test.image.shape is (10000,784).In a 10k batch, it takes 2GB for this layer and lead to OOM\n",
    "batch_size = 50\n",
    "batch_num = int(mnist.test.num_examples / batch_size)\n",
    "test_accuracy = 0\n",
    "    \n",
    "for i in range(batch_num):\n",
    "    batch = mnist.test.next_batch(batch_size)\n",
    "    test_accuracy += accuracy.eval(feed_dict={x: batch[0],\n",
    "                                              y_: batch[1],\n",
    "                                              keep_prob: 1.0})\n",
    "\n",
    "test_accuracy /= batch_num\n",
    "print(\"Test accuracy {0:.3f}%\".format(test_accuracy*100.0))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, elapsed time 0.84 seconds, training accuracy 14.000%\n",
      "step 100, elapsed time 1.58 seconds, training accuracy 92.000%\n",
      "step 200, elapsed time 2.30 seconds, training accuracy 94.000%\n",
      "step 300, elapsed time 3.02 seconds, training accuracy 94.000%\n",
      "step 400, elapsed time 3.74 seconds, training accuracy 92.000%\n",
      "step 500, elapsed time 4.46 seconds, training accuracy 94.000%\n",
      "step 600, elapsed time 5.17 seconds, training accuracy 98.000%\n",
      "step 700, elapsed time 5.90 seconds, training accuracy 98.000%\n",
      "Total training time for 800 batches: 6.61 seconds\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_image, Variable/read)]]\n\t [[Node: Mean_1/_27 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"F:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6860197c073b>\", line 5, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # convolution\n  File \"<ipython-input-2-d0abcb5194e7>\", line 10, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_image, Variable/read)]]\n\t [[Node: Mean_1/_27 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_image, Variable/read)]]\n\t [[Node: Mean_1/_27 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d9792e9c3cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Accuracy on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m print(\"Test accuracy {0:.3f}%\".format(accuracy.eval(feed_dict={\n\u001b[1;32m---> 31\u001b[1;33m     x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})*100.0))\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m     \"\"\"\n\u001b[1;32m--> 570\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_dup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4453\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4454\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4455\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_image, Variable/read)]]\n\t [[Node: Mean_1/_27 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Conv2D', defined at:\n  File \"F:\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6860197c073b>\", line 5, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # convolution\n  File \"<ipython-input-2-d0abcb5194e7>\", line 10, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 630, in conv2d\n    data_format=data_format, name=name)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]\n\t [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](x_image, Variable/read)]]\n\t [[Node: Mean_1/_27 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_79_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, elapsed time 0.01 seconds, training accuracy 20.000%\n",
      "step 100, elapsed time 0.73 seconds, training accuracy 84.000%\n",
      "step 200, elapsed time 1.44 seconds, training accuracy 78.000%\n",
      "step 300, elapsed time 2.28 seconds, training accuracy 90.000%\n",
      "step 400, elapsed time 2.98 seconds, training accuracy 90.000%\n",
      "step 500, elapsed time 3.69 seconds, training accuracy 92.000%\n",
      "step 600, elapsed time 4.40 seconds, training accuracy 96.000%\n",
      "step 700, elapsed time 5.10 seconds, training accuracy 94.000%\n",
      "step 800, elapsed time 5.81 seconds, training accuracy 98.000%\n",
      "step 900, elapsed time 6.51 seconds, training accuracy 92.000%\n",
      "step 1000, elapsed time 7.21 seconds, training accuracy 98.000%\n",
      "step 1100, elapsed time 7.92 seconds, training accuracy 96.000%\n",
      "step 1200, elapsed time 8.62 seconds, training accuracy 96.000%\n",
      "step 1300, elapsed time 9.34 seconds, training accuracy 100.000%\n",
      "step 1400, elapsed time 10.13 seconds, training accuracy 96.000%\n",
      "step 1500, elapsed time 10.87 seconds, training accuracy 96.000%\n",
      "step 1600, elapsed time 11.59 seconds, training accuracy 94.000%\n",
      "step 1700, elapsed time 12.31 seconds, training accuracy 98.000%\n",
      "step 1800, elapsed time 13.02 seconds, training accuracy 98.000%\n",
      "step 1900, elapsed time 13.73 seconds, training accuracy 98.000%\n",
      "step 2000, elapsed time 14.45 seconds, training accuracy 94.000%\n",
      "step 2100, elapsed time 15.15 seconds, training accuracy 96.000%\n",
      "step 2200, elapsed time 15.86 seconds, training accuracy 100.000%\n",
      "step 2300, elapsed time 16.57 seconds, training accuracy 100.000%\n",
      "step 2400, elapsed time 17.29 seconds, training accuracy 100.000%\n",
      "step 2500, elapsed time 18.08 seconds, training accuracy 98.000%\n",
      "step 2600, elapsed time 18.78 seconds, training accuracy 100.000%\n",
      "step 2700, elapsed time 19.50 seconds, training accuracy 100.000%\n",
      "step 2800, elapsed time 20.20 seconds, training accuracy 96.000%\n",
      "step 2900, elapsed time 20.91 seconds, training accuracy 100.000%\n",
      "Total training time for 3000 batches: 21.61 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
